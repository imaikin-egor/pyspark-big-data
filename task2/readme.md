Основная задача - по данным постов в телеграм каналах предсказать количество просмотров этих постов.
Поскольку мы изучаем Spark, акцент в задании - на подготовку фичей на кластере, а не на непосредственно тюнинге модели. Проверяться качество модели тоже будет, но достаточно будет преодолеть довольно простой бейзлайн.

Вот тут лежит шаблон решения https://yadi.sk/d/GBQVSv4VpUdDEA
Там предлагается лишь один из возможных путей решения, можно модифицировать его как угодно.
Данные.
Предоставляется 3 файла:
трейн сет (с количеством просмотров)
тест сет (без количества просмотров)
метаданные каналов
Трейн и тест разбиты по времени. Как прочитать данные можно посмотреть в ноутбуке.
Задание.
Подсчитать фичи для модели, используя только Spark
Фичи можно перевести в pandas и обучить свой любимый алгоритм локально (но не обязательно)
Предсказать им тест сет и побить бейзлайн по целевым метрикам

Метрики.
Поскольку просмотры распределены экспоненциально, предсказывать будем странную величину log(post_views + 100). Вычисляются сразу 4 метрики, но они связаны между собой. Это
RMSPE - Root Mean Squared Percentage Error
MAPE - Mean Absolute Percentage Error
MAE - Mean Absolute Error
RMSE - Root Mean Squared Error

баллы можно получить за следующие пункты.
1 балл за фичу, использующую метаданные каналов (макс 1 балл)
2 балла за фичу, использующую текстовые поля (макс 2 балла) 
1 балл за фичу, использующую window aggregation, до 2 штук, различающихся по смыслу и реализации. Фичи которые можно альтернативно подсчитать групбаем и джойном не засчитываются (макс 2 балла)
-1 балла за грязный код и -1 за отсутствие комментариев

Все фичи должны быть осмысленными для задачи. Поля исходных данных и их простейшие преобразования (математические выражения для числовых, количество символов/слов для текстовых и тд) не засчитываются. Но при этом вы можете их добавлять чтобы улучшить модель
